<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Unsupervised-Learning on KTH Machine Learning Seminars</title>
    <link>https://www.csc.kth.se/cvap/cvg/ml-seminars/tags/unsupervised-learning/</link>
    <description>Recent content in Unsupervised-Learning on KTH Machine Learning Seminars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© Copyright notice</copyright>
    <lastBuildDate>Mon, 12 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.csc.kth.se/cvap/cvg/ml-seminars/tags/unsupervised-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hamed Pirsiavash: Learning with limited labels for visual recognition</title>
      <link>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-11/</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-11/</guid>
      <description>Title: Learning with limited labels for visual recognition
Speaker: Hamed Pirsiavash, University of California, Davis
Date and Time: Monday, June 12, 11am - 12pm
Place: Room 304, Teknikringen 14
Abstract:
We are interested in learning visual representations that are discriminative for semantic image understanding tasks such as object classification, detection, and segmentation in images/videos. A common approach to obtain such features is to use supervised learning. However, this requires manual annotation of images, which is costly, ambiguous, and prone to errors.</description>
    </item>
    
    <item>
      <title>Carl Doersch: Learning and transferring visual representations with few labels: BYOL &#43; CrossTransformers</title>
      <link>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-8/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-8/</guid>
      <description>Title: Learning and transferring visual representations with few labels: BYOL + CrossTransformers
Speaker: Carl Doersch, DeepMind
Date and Time: Tuesday, June 22, 1-2 pm
Place: Zoom Meeting
Meeting ID: 693 9289 5889 Pass code: 259475
Abstract: When encountering novelty, like new tasks and new domains, current visual representations struggle to transfer knowledge if trained on standard tasks like ImageNet classification. This talk explores how to build representations which better capture the visual world, and transfer better to new tasks.</description>
    </item>
    
    <item>
      <title>Mathilde Caron: Self-Supervised Learning of Visual Representations</title>
      <link>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-5/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-5/</guid>
      <description>Title: Self-Supervised Learning of Visual Representations
Speaker: Mathilde Caron, Facebook AI Research
Date and Time: Tuesday, May 18, 1-2 pm
Place: Zoom Meeting
Meeting ID: 628 7889 2739 Pass code: 053004
Abstract: Self-supervised learning is the problem of training deep neural network systems without using any manual annotations. Training deep networks typically requires large amounts of annotated data, which has limited their applications in fields where accessing annotations is difficult. Moreover, manual annotations are biased towards a specific task and towards the annotator&amp;rsquo;s own biases.</description>
    </item>
    
    <item>
      <title>Alyosha Efros: The Revolution Will Not Be Supervised</title>
      <link>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.csc.kth.se/cvap/cvg/ml-seminars/posts/post-6/</guid>
      <description>Title: The Revolution Will Not Be Supervised
Speaker: Alyosha Efros, University of California Berkeley
Date and Time: 2019
Place: Room 304, Teknikringen 14
Abstract: Computer vision has made impressive gains through the use of deep learning models trained with large-scale labeled data. However, labels require expertise and curation and are expensive to collect. Worse, semantic supervision often leads to models that can &amp;ldquo;cheat&amp;rdquo;. Can one discover useful visual representations without the use of explicitly curated labels?</description>
    </item>
    
  </channel>
</rss>
